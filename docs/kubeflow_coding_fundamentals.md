# Kubeflow Basics - The 3 Essential Patterns

## ðŸŽ¯ **MLOps Role: Wrap ML Engineer's Code with Kubeflow**

**The 3 Core Patterns You Need**:
1. **Component** = Wrap one ML script 
2. **Pipeline** = Connect components in order
3. **File I/O** = Pass data between components using `with open()`

---

## ðŸš€ **Essential Imports**

```python
# ACTUAL imports we use in our working pipeline (v1 API):
import kfp                           # Core KFP library
from kfp import dsl                  # Pipeline DSL functions
from kfp.dsl import component        # Component decorator

# Compilation (ACTUAL pattern we use):
# kfp.compiler.Compiler().compile(pipeline_func, 'output.yaml')

# Type Annotations (For proper return types):
from typing import NamedTuple, List, Dict, Any

# Client (For programmatic execution):
from kfp import Client
```

**âš ï¸ HONEST TRUTH: Our project uses KFP v1 API, not v2!**

**ðŸŽ¯ Advanced imports (NOT used in our current implementation but useful to know):**
```python
# File I/O Types (for v2 API - we don't use these yet):
# from kfp.v2.dsl import InputPath, OutputPath, Dataset, Model, Metrics

# Pipeline Control (for v2 API - we don't use these yet): 
# from kfp.v2.dsl import Condition, ParallelFor, ExitHandler

# v2 Compiler (we use v1 pattern instead):
# from kfp.v2 import compiler
```

---

## ï¿½ **2. COMPONENT PATTERN: WRAPPING ML ENGINEER'S CODE**

### The MLOps Approach: Pure Wrapper Pattern

**ML Engineer gives you**: `scripts/data_validator.py`
**You create**: `components/data_validation_component.py`

```python
# âœ… ML Engineer's Code (DON'T TOUCH)
# File: scripts/data_validator.py
class DataValidator:
    def __init__(self, min_records=1000):
        self.min_records = min_records
    
    def validate_dataset(self, df=None):
        # ML logic here - not your concern
        results = {'is_valid': True, 'record_count': len(df)}
        return results

# ðŸ”§ Your MLOps Wrapper (YOUR RESPONSIBILITY)  
# File: components/data_validation_component.py
@component(
    base_image="python:3.9",
    packages_to_install=["pandas", "numpy"]  # What ML engineer needs
)
def data_validation_component(
    # ðŸ“¥ Inputs: What data comes into this step
    min_records: int = 1000,
    input_data: InputPath('Dataset'),
    
    # ï¿½ Outputs: What files this step produces
    validation_report: OutputPath('Metrics'),
    validated_data: OutputPath('Dataset')
    
) -> NamedTuple('ValidationOutput', [('is_valid', bool)]):
    """MLOps wrapper around ML Engineer's DataValidator"""
    
    # ðŸ“ Import ML Engineer's code (don't modify it!)
    sys.path.append('/opt/mlpipeline/launch')
    from scripts.data_validator import DataValidator
    
    # ï¿½ Execute ML Engineer's logic
    validator = DataValidator(min_records=min_records)
    results = validator.validate_dataset()  # ML magic happens here
    
    # ðŸ—‚ï¸ Handle Kubeflow I/O (your MLOps responsibility)
    import pandas as pd
    import json
    
    # Save validation report
    with open(validation_report, 'w') as f:
        json.dump(results, f)
    
    # Copy validated data (if valid)
    if results['is_valid']:
        # In real implementation, you'd copy/process the actual data
        pd.DataFrame({'status': ['validated']}).to_csv(validated_data)
    
    # ï¿½ Return simple status for pipeline decisions
    return (results['is_valid'],)
```

### **ðŸ” MLOps Pattern Breakdown**:
1. **Import ML code**: `from scripts.data_validator import DataValidator`
2. **Execute ML logic**: `validator.validate_dataset()` 
3. **Handle file I/O**: Save results to `OutputPath` files
4. **Return pipeline data**: Simple values for next components

---

## ðŸ—ï¸ **3. PIPELINE PATTERN: ORCHESTRATING ML WORKFLOW**

### Your MLOps Pipeline: Connecting ML Components

```python
@pipeline(
    name='ml-predictive-scaling',
    description='MLOps pipeline wrapping ML Engineer components'
)
def predictive_scaling_pipeline(
    # ðŸŽ›ï¸ Configuration (what changes between runs)
    environment: str = 'dev',
    accuracy_threshold: float = 0.8
):
    """
    MLOps orchestration of ML Engineer's 4-stage workflow:
    1. Data Validation (scripts/data_validator.py)
    2. Feature Engineering (scripts/feature_engineer.py)  
    3. Model Training (scripts/model_trainer.py)
    4. Model Validation (scripts/model_validator.py)
    """
    
    # ðŸ” Stage 1: Wrap ML Engineer's data validation
    data_task = data_validation_component(
        min_records=1000
    )
    
    # ðŸ”§ Stage 2: Only proceed if data is valid (MLOps safety)
    with dsl.Condition(data_task.outputs['is_valid'] == True):
        
        feature_task = feature_engineering_component(
            input_data=data_task.outputs['validated_data']
        )
        
        # ðŸ§  Stage 3: Parallel model training (MLOps efficiency)
        cpu_task = model_training_component(
            model_type='cpu',
            training_data=feature_task.outputs['processed_data']
        )
        
        memory_task = model_training_component(
            model_type='memory', 
            training_data=feature_task.outputs['processed_data']
        )
        
        # âœ… Stage 4: Validate both models
        validation_task = model_validation_component(
            cpu_model=cpu_task.outputs['trained_model'],
            memory_model=memory_task.outputs['trained_model'],
            threshold=accuracy_threshold
        )
```

**ðŸŽ¯ Your MLOps Value**:
- **Conditional Logic**: Skip steps if earlier ones fail
- **Parallel Execution**: Train multiple models simultaneously  
- **Error Handling**: Graceful failure management
- **Configuration**: Easy environment switching
---

## ðŸ“ **4. FILE I/O PATTERNS (MLOps Data Flow Management)**

### **ðŸŽ¯ HONEST TRUTH: We Don't Use KFP v2 File Types - Here's What We Actually Do**

**âŒ What Documentation Usually Shows (but we DON'T use):**
```python
# These are v2 imports we don't actually use:
# from kfp.v2.dsl import InputPath, OutputPath, Dataset, Model, Metrics
```

**âœ… What We Actually Use (MinIO + Simple File Operations):**

```python
@component(base_image="shivapondicherry/forecast-train:latest")
def real_component() -> dict:  # We return dict, not fancy types!
    """How we ACTUALLY handle data flow in our project"""
    
    from minio import Minio
    import pandas as pd
    import pickle
    import json
    
    # ðŸ”Œ Connect to our MinIO storage (our "shared filesystem")
    minio_client = Minio(
        "minio-service.kubeflow.svc.cluster.local:9000",
        access_key="minio", 
        secret_key="minio123",
        secure=False
    )
    
    # ðŸ“¥ DOWNLOAD data from previous component (not InputPath!)
    print("ðŸ“¥ Downloading CSV from MinIO")
    minio_client.fget_object("mlpipeline", "metrics_dataset.csv", "metrics_dataset.csv")
    df = pd.read_csv("metrics_dataset.csv")  # Simple pandas read!
    
    # ðŸ“¥ DOWNLOAD models from previous component (not InputPath!)  
    print("ðŸ“¥ Downloading model from MinIO")
    minio_client.fget_object("mlpipeline", "models/cpu_model.pkl", "cpu_model.pkl")
    with open("cpu_model.pkl", "rb") as f:
        model = pickle.load(f)  # Simple pickle load!
    
    # ðŸ”§ Do our ML work
    results = model.predict(df)
    
    # ðŸ“¤ UPLOAD results for next component (not OutputPath!)
    results_df = pd.DataFrame({'predictions': results})
    results_df.to_csv("predictions.csv", index=False)
    minio_client.fput_object("mlpipeline", "predictions.csv", "predictions.csv")
    
    # ðŸ“¤ UPLOAD metadata as simple JSON (not Metrics type!)
    metadata = {'accuracy': 0.85, 'record_count': len(df)}
    with open("metadata.json", "w") as f:
        json.dump(metadata, f)
    minio_client.fput_object("mlpipeline", "metadata.json", "metadata.json")
    
    # âœ… Return simple dict (not fancy NamedTuple!)
    return {
        'success': True,
        'predictions_file': 'predictions.csv',
        'metadata_file': 'metadata.json',
        'record_count': len(df)
    }
```

**ðŸ” Why This Actually Works Better Than Documentation:**

1. **ðŸ“ CSV Files**: We use `pd.read_csv()` and `pd.to_csv()` - simple and reliable
2. **ðŸ¤– Models**: We use `pickle.load()` and `pickle.dump()` - standard Python approach  
3. **ðŸ“Š Metrics**: We use `json.dump()` and `json.load()` - easy to read anywhere
4. **ðŸ’¾ Storage**: MinIO acts like a shared drive - all components can read/write
5. **ðŸ”„ Data Flow**: Component A uploads â†’ Component B downloads â†’ works perfectly!

**ðŸŽ¯ Real Pattern We Use**: MinIO as "Component Messaging System" - not fancy KFP types!

---

## ðŸ”„ **5. DEPLOYMENT PATTERNS (MLOps Production Responsibility)**

### Pattern 1: Compile Pipeline (Python â†’ YAML)

```python
# Your deployment script: deploy_pipeline.py
from kfp.v2 import compiler

def deploy_ml_pipeline():
    """MLOps: Convert ML pipeline to production format"""
    
    # ðŸ“¦ Compile Python pipeline to YAML
    compiler.Compiler().compile(
        pipeline_func=predictive_scaling_pipeline,
        package_path='ml_pipeline.yaml'
    )
    print("âœ… Pipeline ready for Kubeflow deployment")

if __name__ == "__main__":
    deploy_ml_pipeline()
```

### Pattern 2: Execute Pipeline (Run in Production)

```python
# Your execution script: run_pipeline.py  
from kfp import Client

def run_production_pipeline():
    """MLOps: Execute pipeline in Kubeflow cluster"""
    
    # ðŸ”Œ Connect to Kubeflow
    client = Client(host='http://kubeflow-cluster:8080')
    
    # ðŸ“ Create/get experiment
    try:
        experiment = client.create_experiment('predictive-scaling-prod')
    except:
        experiment = client.get_experiment(experiment_name='predictive-scaling-prod')
    
    # ðŸš€ Submit pipeline run
    run = client.run_pipeline(
        experiment_id=experiment.id,
        job_name=f'ml-pipeline-{int(time.time())}',
        pipeline_package_path='ml_pipeline.yaml',
        params={                                    # Environment-specific settings
            'environment': 'prod',
            'accuracy_threshold': 0.85
        }
    )
    
    print(f"ðŸŽ¯ Pipeline running: {run.id}")
    return run
```

### Pattern 3: Environment Configuration (Dev vs Prod)

```python
# Your config management
def get_environment_config(env: str):
    """MLOps: Manage different environments"""
    
    configs = {
        'dev': {
            'data_source': 'dev-bucket/small-dataset.csv',
            'accuracy_threshold': 0.70,           # Relaxed for development
            'retries': 3,                         # More retries for debugging
            'base_image': 'python:3.9-slim'      # Smaller image for dev
        },
        'prod': {
            'data_source': 'prod-bucket/full-dataset.csv', 
            'accuracy_threshold': 0.85,           # Strict for production
            'retries': 1,                         # Fail fast in production
            'base_image': 'your-company/ml-prod:latest'  # Optimized prod image
        }
    }
    
    return configs[env]

@pipeline(name='configurable-ml-pipeline')
def configurable_pipeline(environment: str = 'dev'):
    """Pipeline that adapts to different environments"""
    
    config = get_environment_config(environment)
    
    # Use environment-specific settings
    data_task = data_validation_component(
        data_source=config['data_source']
    ).set_retry(config['retries'])
    
    model_task = model_training_component(
        accuracy_threshold=config['accuracy_threshold']
    )
```

---

## ðŸ› ï¸ **6. ERROR HANDLING PATTERNS (MLOps Reliability)**

### Pattern: Graceful Component Failure

```python
@component(base_image="python:3.9")
def robust_mlops_component(
    input_data: InputPath('Dataset'),
    output_data: OutputPath('Dataset'),
    error_log: OutputPath('Metrics')
) -> NamedTuple('ComponentOutput', [('success', bool)]):
    """MLOps pattern: Always return valid outputs, even on failure"""
    
    try:
        # Import and execute ML Engineer's code
        from scripts.ml_logic import MLProcessor
        
        processor = MLProcessor()
        results = processor.process_data(input_data)
        
        # Save results
        results.to_csv(output_data, index=False)
        
        # Log success
        with open(error_log, 'w') as f:
            json.dump({'status': 'success', 'records': len(results)}, f)
            
        return (True,)
        
    except Exception as e:
        # MLOps responsibility: Handle failures gracefully
        print(f"Component failed: {str(e)}")
        
        # Create empty outputs so pipeline doesn't crash
        pd.DataFrame().to_csv(output_data, index=False)
        
        with open(error_log, 'w') as f:
            json.dump({'status': 'failed', 'error': str(e)}, f)
            
        return (False,)  # Let pipeline know this failed
```

### Pattern: Conditional Pipeline Execution

```python
@pipeline(name='safe-ml-pipeline')
def safe_pipeline():
    """MLOps pattern: Skip steps if previous ones failed"""
    
    # Step 1: Data validation
    validation_task = data_validation_component()
    
    # Step 2: Only continue if validation passed
    with dsl.Condition(validation_task.outputs['success'] == True):
        
        training_task = model_training_component(
            input_data=validation_task.outputs['validated_data']
        )
        
        # Step 3: Only deploy if training succeeded  
        with dsl.Condition(training_task.outputs['success'] == True):
            deployment_task = model_deployment_component(
                model=training_task.outputs['trained_model']
            )
```

---

## ðŸŽ“ **MLOPS QUICK REFERENCE**

### âœ… Your MLOps Checklist:

1. **ðŸ“¦ Component Wrapper Pattern**:
   ```python
   @component(base_image="python:3.9", packages_to_install=[...])
   def mlops_wrapper():
       from scripts.ml_code import MLClass  # Import ML Engineer's code
       result = MLClass().process()         # Execute ML logic
       # Handle Kubeflow I/O
   ```

2. **ðŸ”— Pipeline Orchestration Pattern**:
   ```python
   @pipeline(name='ml-pipeline')
   def ml_pipeline():
       task1 = component1()
       task2 = component2(input=task1.outputs['data'])
   ```

3. **ðŸš€ Deployment Pattern**:
   ```python
   compiler.Compiler().compile(pipeline_func=ml_pipeline, package_path='pipeline.yaml')
   client.run_pipeline(pipeline_package_path='pipeline.yaml')
   ```

4. **ðŸ›¡ï¸ Error Handling Pattern**:
   ```python
   with dsl.Condition(task.outputs['success'] == True):
       next_task = next_component()
   ```

### ðŸŽ¯ Key MLOps Principles:
- **Don't modify ML Engineer's logic** - just wrap it
- **Always handle failures gracefully** - return valid outputs
- **Use conditional execution** - skip steps if previous failed
- **Manage environments** - different configs for dev/prod
- **Focus on orchestration** - let ML Engineers focus on algorithms

This streamlined guide focuses on **your MLOps responsibilities**: taking ML code and making it production-ready with Kubeflow!
```python
@dsl.pipeline(                                    # ðŸ·ï¸ "This is a complete workflow"
    name='ml-predictive-scaling-pipeline',       # ðŸ“ Name for the assembly line
    description='Predicts Kubernetes resource needs using ML',  # ðŸ“– What it does
    pipeline_root='gs://your-bucket/pipeline-root'  # ðŸ“ Where to store files
)
def predictive_scaling_pipeline(
    
    # ðŸŽ›ï¸ PIPELINE SETTINGS - Things you can adjust when running
    environment: str = 'dev',               # Which environment (dev/prod)
    accuracy_threshold: float = 0.8,        # How accurate model needs to be
    retrain_schedule: str = 'weekly'         # How often to retrain
):
    """
    ðŸŽ¯ PURPOSE: Complete ML workflow for predicting resource usage
    ðŸ“Š USE CASE: Automatically predict if we need more CPU/memory next week
    ðŸ”„ WORKFLOW: Raw Data â†’ Clean Data â†’ Train Models â†’ Validate â†’ Deploy
    """
    
    # ðŸ—ï¸ STEP 1: Check if our data is good quality
    print("Step 1: Validating data quality...")
    data_validation_task = data_validation_component(
        min_records=1000,                    # Need at least 1000 data points
        quality_threshold=0.95               # 95% of data must be valid
    )
    
    # ðŸ”§ STEP 2: Only continue if data is good (conditional execution)
    with dsl.Condition(data_validation_task.outputs['is_valid'] == True):
        
        print("Step 2: Preparing features for ML...")
        feature_engineering_task = feature_engineering_component(
            input_data=data_validation_task.outputs['validated_data'],  # Use clean data
            feature_window='7d'              # Look at 7-day patterns
        )
        
        # ðŸ§  STEP 3: Train models (parallel - both happen at same time)
        print("Step 3: Training prediction models...")
        
        # Train CPU prediction model
        cpu_training_task = train_prophet_model_component(
            model_type='cpu',                # Predicting CPU usage
            training_data=feature_engineering_task.outputs['processed_data']
        )
        
        # Train Memory prediction model (happens simultaneously)
        memory_training_task = train_prophet_model_component(
            model_type='memory',             # Predicting memory usage  
            training_data=feature_engineering_task.outputs['processed_data']
        )
        
        # ðŸ§ª STEP 4: Test both models (waits for both training to finish)
        print("Step 4: Validating model accuracy...")
        model_validation_task = model_validation_component(
            cpu_model=cpu_training_task.outputs['trained_model'],
            memory_model=memory_training_task.outputs['trained_model'],
            accuracy_threshold=accuracy_threshold  # Use the threshold we set
        )
```

**ðŸ” Breaking Down the Pipeline Flow:**

1. **`@dsl.pipeline`**: Tells Kubeflow this is a complete workflow
2. **Pipeline parameters**: Settings you can change when running (like recipe variations)
3. **Sequential steps**: Each step waits for previous to finish
4. **Conditional logic**: "Only do Step 2 if Step 1 succeeded"
5. **Parallel execution**: CPU and memory training happen simultaneously (faster!)
6. **Data flow**: Each step uses outputs from previous steps

**ðŸŽ¯ Real-world analogy**: Like a smart cooking recipe:
- "Only start cooking if ingredients are fresh" (conditional)
- "While sauce simmers, chop vegetables" (parallel)
- "Use the chopped vegetables from step 2" (data flow)

### Why This Structure Matters:

**âŒ Without Pipeline (Manual Process):**
1. You run data validation script
2. Check if it worked
3. If good, manually run feature engineering
4. Wait for it to finish
5. Manually start model training
6. Wait... monitor... fix problems...

**âœ… With Pipeline (Automated):**
1. Click "Run Pipeline"
2. Kubeflow automatically runs all steps in correct order
3. Handles failures, retries, and parallel execution
4. You get notified when done or if problems occur

### Advanced Pipeline Patterns (Optional - But Useful to Know):

```python
@dsl.pipeline(name='advanced-ml-pipeline')
def advanced_pipeline():
    
    # âš¡ PARALLEL EXECUTION - Two things happen at the same time
    task1 = component_a()                    # Starts immediately
    task2 = component_b()                    # Also starts immediately (parallel!)
    
    # â›“ï¸ SEQUENTIAL DEPENDENCY - Wait for task1 to finish first
    task3 = component_c(
        input_from_a=task1.outputs['result']  # Can't start until task1 finishes
    )
    
    # ðŸ”€ CONDITIONAL EXECUTION - Only run if something succeeded
    with dsl.Condition(task1.outputs['success'] == True):
        task4 = component_d()                # Only runs if task1 was successful
    
    # ðŸ”„ LOOP EXECUTION - Run same component multiple times
    with dsl.ParallelFor(['service1', 'service2', 'service3']) as service:
        # This runs once for each service (parallel!)
        service_task = train_service_model(service_name=service)
    
    # ðŸ§¹ CLEANUP - Always runs at the end (even if pipeline fails)
    with dsl.ExitHandler(cleanup_component()):
        main_task = main_processing_component()
```

**ðŸ” When to Use Each Pattern:**
- **Parallel**: Train CPU and memory models simultaneously (saves time)
- **Sequential**: Can't validate model until training finishes
- **Conditional**: Skip deployment if model accuracy is too low
- **Loop**: Train separate models for different microservices
- **Cleanup**: Delete temporary files, send notifications

---

## ðŸŒ **5. ENVIRONMENT VARIABLES - CONFIGURING YOUR COMPONENTS**

### Why Do We Need Environment Variables?

**Think of environment variables as "settings" or "configuration" for your components:**

**ðŸ  Real-world analogy**: Your thermostat settings
- In winter: Set to 70Â°F (heating mode)
- In summer: Set to 72Â°F (cooling mode)
- Different settings for different situations, same thermostat

**ðŸ’» In ML Components**: Different behavior for different environments
- **Development**: Use small datasets, relaxed accuracy requirements
- **Production**: Use full datasets, strict accuracy requirements

### Component Environment Variables (Simple Pattern):

```python
@component(base_image="python:3.9")
def component_with_env_vars(
    api_endpoint: str,                       # Where to get data from
    output_data: OutputPath('Dataset')
):
    """
    ðŸŽ¯ PURPOSE: Component that adapts behavior based on environment
    ðŸ“Š USE CASE: Connect to different data sources in dev vs prod
    """
    import os
    
    # ðŸ”§ Set environment variables (component configuration)
    os.environ['API_ENDPOINT'] = api_endpoint    # Where to fetch data
    os.environ['LOG_LEVEL'] = 'INFO'             # How much logging to show
    os.environ['TIMEOUT'] = '30'                 # How long to wait for data
    
    # ðŸ“– Use environment variables in your code
    endpoint = os.getenv('API_ENDPOINT')         # Get the API endpoint
    log_level = os.getenv('LOG_LEVEL', 'WARNING')  # Default to WARNING if not set
    timeout = int(os.getenv('TIMEOUT', '10'))    # Default to 10 seconds
    
    print(f"Connecting to: {endpoint}")
    print(f"Log level: {log_level}")
    print(f"Timeout: {timeout} seconds")
    
    # ðŸ”Œ Your component logic here (connect to API, process data, etc.)
    # This would actually fetch data from the endpoint
    response = requests.get(endpoint, timeout=timeout)
    # ... process response and save to output_data
```

### Pipeline-Level Configuration (Managing Multiple Environments):

```python
@dsl.pipeline(name='configurable-pipeline')
def configurable_pipeline(config: dict = None):
    """
    ðŸŽ¯ PURPOSE: Pipeline that behaves differently in dev vs prod
    ðŸ“Š USE CASE: Same workflow, different settings based on environment
    """
    
    if config is None:  # Default configuration
        config = {
            'environments': {
                'dev': {
                    'data_source': 'small-test-dataset.csv',    # Smaller data for testing
                    'accuracy_threshold': 0.70,                 # More lenient accuracy
                    'retries': 3,                               # More retries for debugging
                    'model_registry': 'dev-models/'
                },
                'prod': {
                    'data_source': 'full-production-data.csv',  # Complete dataset
                    'accuracy_threshold': 0.85,                 # Strict accuracy requirement
                    'retries': 1,                               # Fail fast in production
                    'model_registry': 'prod-models/'
                }
            }
        }
    
    # ðŸŽ¯ Choose environment settings
    env = 'prod'  # Could be passed as parameter
    env_config = config['environments'][env]
    
    # ðŸ”§ Use environment-specific settings
    data_task = data_loader_component(
        data_source=env_config['data_source']           # Different data sources
    )
    
    model_task = model_trainer_component(
        model_registry=env_config['model_registry'],    # Different model storage
        accuracy_threshold=env_config['accuracy_threshold']  # Different quality bars
    ).set_retry(env_config['retries'])                  # Different retry policies
```

**ðŸ” Common Environment Variables in Kubeflow:**

```python
# ðŸ·ï¸ Kubernetes and Kubeflow automatically set these
namespace = os.getenv('POD_NAMESPACE', 'default')      # Which Kubernetes namespace
pod_name = os.getenv('POD_NAME', 'unknown')            # Name of the running pod
pipeline_run_id = os.getenv('KFP_RUN_ID')              # Unique ID for this pipeline run
pipeline_task_name = os.getenv('KFP_TASK_NAME')        # Name of current component

print(f"Running in namespace: {namespace}")
print(f"Pipeline run ID: {pipeline_run_id}")
```

**ðŸŽ¯ Why This Matters for Our Project:**
- **Development**: Test with small datasets, connect to dev MinIO instance
- **Production**: Use full historical data, connect to production MinIO
- **Different accuracy requirements**: 70% OK for dev, need 85% for prod

---

## ðŸ”„ **6. RUNNING YOUR PIPELINE - FROM CODE TO EXECUTION**

### Why Do We Need to Compile Pipelines?

**ðŸ—ï¸ Think of compilation like building blueprints:**
- **Your Python code**: Architect's drawings (ideas and concepts)
- **Compiled YAML**: Construction blueprints (exact specifications)
- **Kubeflow cluster**: Construction site (where work actually happens)

**ðŸŽ¯ You write Python code because it's easier to think in, but Kubeflow needs YAML to execute**

### Step 1: Compilation (Convert Python to YAML):

```python
# compile_pipeline.py
from kfp.v2 import compiler

def compile_my_pipeline():
    """
    ðŸŽ¯ PURPOSE: Convert Python pipeline to YAML that Kubeflow can run
    ðŸ“Š USE CASE: Like exporting your Word document to PDF for sharing
    """
    
    print("Converting Python pipeline to YAML...")
    
    # ðŸ“¦ This takes your Python function and creates a YAML file
    compiler.Compiler().compile(
        pipeline_func=predictive_scaling_pipeline,    # Your Python pipeline function
        package_path='my_pipeline.yaml'              # Output file name
    )
    
    print("âœ… Pipeline compiled successfully!")
    print("ðŸ“ Created file: my_pipeline.yaml")

# Run this to create your YAML file
if __name__ == "__main__":
    compile_my_pipeline()
```

### Step 2: Upload and Execute (Run the Pipeline):

```python
# run_pipeline.py
from kfp import Client
import time

def run_my_pipeline():
    """
    ðŸŽ¯ PURPOSE: Submit pipeline to Kubeflow cluster for execution
    ðŸ“Š USE CASE: Like sending your document to the printer
    """
    
    # ðŸ”Œ Connect to Kubeflow (like connecting to a printer)
    client = Client(
        host='http://localhost:8080'  # Replace with your Kubeflow URL
        # For cloud: host='https://your-kubeflow-cluster.com'
    )
    
    # ðŸ“ Create a project folder (experiment) to organize runs
    try:
        experiment = client.create_experiment('my-ml-project')
        print("âœ… Created new experiment: my-ml-project")
    except:
        # If experiment already exists, use it
        experiment = client.get_experiment(experiment_name='my-ml-project')
        print("ðŸ“‚ Using existing experiment: my-ml-project")
    
    # ðŸš€ Submit the pipeline for execution
    run = client.run_pipeline(
        experiment_id=experiment.id,
        job_name=f'predictive-scaling-{int(time.time())}',  # Unique name with timestamp
        pipeline_package_path='my_pipeline.yaml',           # The YAML file we created
        params={                                            # Settings for this run
            'environment': 'dev',
            'accuracy_threshold': 0.80,
            'retrain_schedule': 'weekly'
        }
    )
    
    print(f"ðŸŽ¯ Pipeline submitted successfully!")
    print(f"ðŸ“‹ Run ID: {run.id}")
    print(f"ðŸ”— Check progress at: http://localhost:8080/#/runs/details/{run.id}")
    
    return run

# Actually run the pipeline
if __name__ == "__main__":
    pipeline_run = run_my_pipeline()
```

### Step 3: Command Line Execution (Alternative Method):

```bash
# ðŸ› ï¸ Alternative: Use command line instead of Python scripts

# Step 1: Compile pipeline
python -m kfp dsl compile --py my_pipeline.py --output my_pipeline.yaml
echo "âœ… Pipeline compiled to YAML"

# Step 2: Upload pipeline to Kubeflow
kfp pipeline upload --pipeline-name my-predictive-scaling my_pipeline.yaml
echo "âœ… Pipeline uploaded to Kubeflow"

# Step 3: Create experiment (project folder)
kfp experiment create my-ml-experiments
echo "âœ… Experiment created"

# Step 4: Run pipeline
kfp run submit \
  --experiment-name my-ml-experiments \
  --run-name "daily-training-$(date +%Y%m%d)" \
  --pipeline-name my-predictive-scaling \
  --params environment=prod,accuracy_threshold=0.85

echo "ðŸš€ Pipeline is now running!"

# Step 5: Check status
kfp run list --experiment-name my-ml-experiments
```

### Monitoring Your Running Pipeline:

```python
def check_pipeline_status(run_id):
    """
    ðŸŽ¯ PURPOSE: Check if your pipeline is still running or finished
    ðŸ“Š USE CASE: Like checking if your food delivery has arrived
    """
    client = Client()
    
    # ðŸ“Š Get current status
    run = client.get_run(run_id)
    status = run.run.status
    
    print(f"Pipeline status: {status}")
    
    if status == "Running":
        print("â³ Pipeline is still executing...")
        print("ðŸ’¡ Check Kubeflow UI for detailed progress")
    elif status == "Succeeded":
        print("âœ… Pipeline completed successfully!")
        print("ðŸ“ Check output artifacts in MinIO/S3")
    elif status == "Failed":
        print("âŒ Pipeline failed!")
        print("ðŸ” Check component logs for error details")
    
    return status

def wait_for_completion(run_id):
    """
    ðŸŽ¯ PURPOSE: Wait for pipeline to finish (like waiting for download to complete)
    ðŸ“Š USE CASE: Don't want to keep checking manually every 5 minutes
    """
    client = Client()
    
    print("â³ Waiting for pipeline to complete...")
    # This will wait up to 1 hour (3600 seconds)
    client.wait_for_run_completion(run_id, timeout=3600)
    
    final_status = check_pipeline_status(run_id)
    return final_status
```

**ðŸ” What Happens When You Run a Pipeline:**

1. **Kubeflow reads your YAML**: "I need to run these 4 components in this order"
2. **Creates Kubernetes pods**: Like hiring workers for each task
3. **Runs components**: Each worker does their specific job
4. **Manages data flow**: Passes results between workers automatically
5. **Handles failures**: Retries failed tasks, reports problems
6. **Stores results**: Saves all outputs (models, reports) for later use

**ðŸŽ¯ Real-world analogy**: Like submitting a complex order to a restaurant:
- You place order (submit pipeline)
- Kitchen coordinates multiple chefs (components)
- Each chef does their part (data validation, model training, etc.)
- Manager ensures everything happens in right order (Kubeflow orchestration)
- You get notified when meal is ready (pipeline completion notification)

---

## ðŸŽ“ **QUICK START CHECKLIST FOR BEGINNERS**

### âœ… To Get Started with Kubeflow, You Need:

1. **ðŸ“ Write Components** (the individual tasks)
   - Use `@component` decorator
   - Define inputs and outputs clearly
   - Keep each component focused on ONE job

2. **ðŸ”— Connect Components** (build the workflow)
   - Use `@dsl.pipeline` decorator  
   - Connect outputs of one component to inputs of next
   - Add conditions for error handling

3. **ðŸ“¦ Compile to YAML** (make it runnable)
   - Use `compiler.Compiler().compile()`
   - Creates `.yaml` file that Kubeflow understands

4. **ðŸš€ Execute Pipeline** (actually run it)
   - Upload YAML to Kubeflow
   - Submit run with parameters
   - Monitor progress through UI or CLI

### ðŸŽ¯ **Most Important Concepts to Remember:**

- **Components** = Individual LEGO blocks (one task each)
- **Pipelines** = Instructions for connecting the blocks  
- **Artifacts** = Files passed between components
- **Parameters** = Settings you can change when running
- **Compilation** = Converting Python to YAML
- **Execution** = Actually running the workflow

### ðŸ’¡ **Start Simple:**
Begin with a 2-component pipeline:
1. Component 1: Load and validate data
2. Component 2: Print summary statistics

Once that works, add more components gradually!

**ðŸŽ¯ Remember**: You don't need to understand every detail to get started. Focus on the basics and build up your knowledge as you practice!

---

## ðŸŽ›ï¸ **7. RESOURCE MANAGEMENT & OPTIMIZATION**

### Component Resource Settings:
```python
@component(base_image="python:3.9")
def resource_optimized_component():
    pass

# In pipeline definition
def resource_aware_pipeline():
    # Lightweight component
    data_validation_task = data_validation_component().set_cpu_limit('500m').set_memory_limit('1Gi')
    
    # Resource-intensive component
    model_training_task = train_model_component() \
        .set_cpu_limit('4') \
        .set_memory_limit('8Gi') \
        .set_gpu_limit('1')
    
    # Custom node selection
    training_task = train_large_model_component() \
        .add_node_selector_constraint('node-type', 'compute-optimized') \
        .set_retry(3)
```

### Advanced Resource Configuration:
```python
def advanced_resource_pipeline():
    from kubernetes import client as k8s_client
    
    # Custom tolerations for dedicated nodes
    training_task = train_model_component()
    training_task.container.add_env_variable(
        k8s_client.V1EnvVar(name='CUDA_VISIBLE_DEVICES', value='0')
    )
    
    # Add tolerations
    training_task.add_toleration(
        k8s_client.V1Toleration(
            key='ml-training',
            operator='Equal',
            value='true',
            effect='NoSchedule'
        )
    )
```

---

## ðŸš¨ **8. ERROR HANDLING & DEBUGGING**

### Component Error Handling:
```python
@component(base_image="python:3.9")
def robust_component(
    input_data: InputPath('Dataset'),
    output_data: OutputPath('Dataset'),
    error_log: OutputPath('Artifact')
) -> NamedTuple('ComponentOutput', [('success', bool), ('error_message', str)]):
    """Component with comprehensive error handling"""
    import traceback
    import pandas as pd
    
    try:
        # Validate inputs
        if not os.path.exists(input_data):
            raise FileNotFoundError(f"Input data not found: {input_data}")
        
        # Main logic
        df = pd.read_csv(input_data)
        
        if len(df) == 0:
            raise ValueError("Input dataset is empty")
        
        # Process data
        processed_df = df.dropna()
        processed_df.to_csv(output_data, index=False)
        
        # Success
        with open(error_log, 'w') as f:
            f.write("SUCCESS: Component completed without errors")
        
        return (True, "")
        
    except Exception as e:
        # Log detailed error
        error_details = {
            'error_type': type(e).__name__,
            'error_message': str(e),
            'traceback': traceback.format_exc(),
            'input_data_path': input_data,
            'timestamp': str(datetime.now())
        }
        
        # Write error log
        with open(error_log, 'w') as f:
            json.dump(error_details, f, indent=2)
        
        # Create empty output to satisfy Kubeflow
        with open(output_data, 'w') as f:
            f.write("")
        
        # Return error information
        return (False, str(e))
```

### Pipeline Error Handling:
```python
@dsl.pipeline(name='robust-pipeline')
def error_resilient_pipeline():
    
    # Component with retries
    data_task = data_loader_component().set_retry(3)
    
    # Conditional execution based on success
    with dsl.Condition(data_task.outputs['success'] == True):
        # Continue only if data loading succeeded
        processing_task = data_processing_component(
            input_data=data_task.outputs['output_data']
        )
        
        # Handle processing failure
        with dsl.Condition(processing_task.outputs['success'] == False):
            # Fallback component
            fallback_task = fallback_processing_component()
    
    # Exit handler for cleanup
    with dsl.ExitHandler(cleanup_component()):
        main_workflow()
```

---

## ðŸ” **9. MONITORING & LOGGING**

### Component Logging:
```python
@component(base_image="python:3.9")
def logged_component():
    """Component with comprehensive logging"""
    import logging
    import sys
    
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        stream=sys.stdout
    )
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("Component started")
        
        # Your logic here
        logger.info("Processing data...")
        # process_data()
        
        logger.info("Data processing completed successfully")
        
    except Exception as e:
        logger.error(f"Component failed: {str(e)}")
        raise
    
    finally:
        logger.info("Component finished")
```

### Monitoring Integration:
```python
@component(
    base_image="python:3.9",
    packages_to_install=["prometheus-client"]
)
def monitored_component():
    """Component with Prometheus metrics"""
    from prometheus_client import Counter, Histogram, push_to_gateway
    import time
    
    # Define metrics
    processing_counter = Counter('component_processing_total', 'Total processing count')
    processing_duration = Histogram('component_processing_duration_seconds', 'Processing duration')
    
    start_time = time.time()
    
    try:
        # Your component logic
        processing_counter.inc()
        
        # Simulate work
        time.sleep(2)
        
        # Record duration
        duration = time.time() - start_time
        processing_duration.observe(duration)
        
        # Push metrics to Prometheus gateway
        push_to_gateway('prometheus-pushgateway:9091', job='kubeflow-component', registry=registry)
        
    except Exception as e:
        # Record failure metric
        failure_counter = Counter('component_failures_total', 'Total failures')
        failure_counter.inc()
        raise
```

---

## ðŸ§ª **10. TESTING PATTERNS**

### Component Unit Testing:
```python
# test_components.py
import tempfile
import pandas as pd
from your_components import data_processing_component

def test_data_processing_component():
    """Test component logic"""
    
    # Create test input data
    test_data = pd.DataFrame({
        'timestamp': pd.date_range('2023-01-01', periods=100, freq='H'),
        'cpu_usage': [0.5 + 0.1 * i for i in range(100)]
    })
    
    with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as input_file:
        test_data.to_csv(input_file.name, index=False)
        
        with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as output_file:
            
            # Execute component
            result = data_processing_component.python_func(
                input_data=input_file.name,
                processed_data=output_file.name,
                threshold=0.6
            )
            
            # Assert results
            assert result[0] == True  # Success
            
            # Check output data
            output_df = pd.read_csv(output_file.name)
            assert len(output_df) > 0
            assert output_df['cpu_usage'].min() >= 0.6
```

### Pipeline Integration Testing:
```python
def test_pipeline_integration():
    """Test pipeline compilation and basic validation"""
    from kfp.v2 import compiler
    
    # Test compilation
    try:
        compiler.Compiler().compile(
            pipeline_func=predictive_scaling_pipeline,
            package_path='test_pipeline.yaml'
        )
        print("Pipeline compilation successful")
    except Exception as e:
        raise AssertionError(f"Pipeline compilation failed: {e}")
    
    # Validate generated YAML
    with open('test_pipeline.yaml', 'r') as f:
        pipeline_spec = f.read()
        assert 'data_validation_component' in pipeline_spec
        assert 'train_model_component' in pipeline_spec
```

This comprehensive guide covers all the foundational Kubeflow patterns you'll need for building robust ML pipelines! Each section includes practical examples that you can adapt for your predictive scaling use case.
